{"posts":[{"title":"redis基础结构","text":"Redis入门 （NoSQL, Not Only SQL） 非关系型数据库 关系型数据库：以 表格 的形式存在，以 行和列 的形式存取数据，一系列的行和列被称为表，无数张表组成了 数据库。支持复杂的 SQL 查询，能够体现出数据之间、表之间的关联关系；也支持事务，便于提交或者回滚。 非关系型数据库：以 key-value 的形式存在，可以想象成电话本的形式，人名（key）对应电话号码（value）。不需要写一些复杂的 SQL 语句，不需要经过 SQL 的重重解析，性能很高；可扩展性也比较强，数据之间没有耦合性，需要新加字段就直接增加一个 key-value 键值对即可。 Redis 是 速度极快的、基于内存的，键值型 NoSQL 数据库。 为什么这么快？ 完全基于内存操作。 使用非阻塞的 IO 多路复用机制。 数据结构简单，对数据操作也简单。 使用单线程，避免了上下文切换和竞争产生的消耗。 支持多种数据类型，包括 String、Hash、List、Set、ZSet 等。 IO 多路复用机制 Redis 使用的是 IO 多路复用机制 来处理 高并发请求，这使得它能在 单线程 模式下仍然保持高吞吐量。 🔹 Redis 为什么要用 IO 多路复用？ Redis 是单线程的，但仍然能高效处理大量连接，这依赖于 IO 多路复用。 传统的 阻塞 IO 方式，每次只能处理一个连接，性能受限。 多路复用可以 同时监听多个客户端请求，只处理活跃连接，减少 CPU 空转。 🔹 Redis 的 IO 多路复用机制 Redis 采用 epoll（Linux）或 select（Windows） 作为 IO 多路复用技术，主要使用 aeEventLoop 事件处理机制： 主线程通过 epoll/select/kqueue 监听多个客户端连接 当某个连接有数据可读（如命令请求），Redis 触发相应的回调函数 回调函数读取请求，处理命令，返回结果 继续监听新的请求，不会阻塞在某个请求上 Redis 使用 事件驱动模型，主要有： 可读事件（AE_READABLE）：当客户端有数据可读时触发。 可写事件（AE_WRITABLE）：当客户端可以写数据时触发。 文件事件（File Event）：通过 epoll 监听 多个 socket 连接。 时间事件（Time Event）：用于定时任务（比如 key 过期检测）。 🔹 Redis 多路复用示意图 1234567891011[多个客户端] │ ▼[epoll/select 监听] │ ├── 客户端 A 可读 -&gt; 触发回调 -&gt; 读取数据 ├── 客户端 B 可写 -&gt; 触发回调 -&gt; 发送数据 ├── 客户端 C 可读 -&gt; 触发回调 -&gt; 读取数据 │ ▼[主线程执行 Redis 命令逻辑] Redis的基础结构类型 Key结构 让 Redis 的 key 形成层级结构，使用 : 隔开：项目名:业务名:类型:id。 123set blog:user:1 '{&quot;id&quot;:1, &quot;name&quot;:&quot;Jack&quot;, &quot;age&quot;:22}'set blog:user:2 '{&quot;id&quot;:2, &quot;name&quot;:&quot;Mike&quot;, &quot;age&quot;:23}'set blog:article:1 '{&quot;id&quot;:1, &quot;title&quot;:&quot;Spring&quot;}' String类型 Key Value blog:user:1 ‘{“id”:1, “name”:“Jack”, “age”:22}’ blog:user:2 ‘{“id”:2, “name”:“Mike”, “age”:23}’ 分配策略： Java 的 String 是不可变的，无法修改。Redis 的 String 是动态的，可以修改的。Redis 的 String 在内部结构实现上类似于 Java 的 ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配。如图所示，当前字符串实际分配的空间为 capacity，一般高于实际的字符串长度 len。当字符串长度小于 1M 时，扩容是对现有空间的成倍增长；如果长度超过 1M 时，扩容一次只会多增加 1M 的空间。String 的最大长度为 512M。 Hash结构 list结构 List 类似 Java 中的 LinkedList，可以看作一个双向链表（有序可重复）。使用 List 可以对链表的两端进行 push 和 pop 操作、读取单个或多个元素、根据值查找或删除元素、支持正向检索和反向检索。 栈：LPUSH + LPOP 或 RPUSH + RPOP。 队列：LPUSH + RPOP 或 RPUSH + LPOP。 Set结构 SADD key member [member ...] ：向 Set 中添加一个或多个元素。 SMEMBERS key ：获取指定 Set 中的所有元素。 SISMEMBER key member ：判断 Set 中是否存在指定元素。 SCARD key ：返回 Set 中的元素个数。 SREM key member [member ...] ：移除 Set 中的指定元素。 SINTER key [key ...] ：求 n 个 key 间的交集。 SDIFF key [key ...] ：求 n 个 key 间的差集。 SUNION key [key ...] ：求 n 个 key 间的并集。 Redis 的 Set 类似 HashSet，可以看作一个 value 为 null 的 HashMap；其特征也与 HashSet 类似：无序不可重复，支持 交集、并集、差集等功能。 ZSet Redis 的 ZSet 是一个可排序的 Set 集合，类似 ZSet。ZSet 的每一个元素都带有一个 score 属性，可以基于 score 属性对元素排序。 ZADD key [score member ...] ：以 score 为权重向 ZSet 中添加一个或多个元素，如果存在则更新 score。 ZREM key member [member ...] ：删除 ZSet 中的指定元素。 ZCARD key ：返回 ZSet 中的元素个数。 ZSCORE key member ：获取 ZSet 中指定元素的 score 值。 ZADD key [score member ...] ：以 score 为权重向 ZSet 中添加一个或多个元素，如果存在则更新 score。 ZREM key member [member ...] ：删除 ZSet 中的指定元素。 ZCARD key ：返回 ZSet 中的元素个数。 ZSCORE key member ：获取 ZSet 中指定元素的 score 值。 ZRANGEBYSCORE key min max ：按照 score 排序后，获取 指定 score 范围 内的元素。 ZINTER numberKeys key [key ...] ｜ ZDIFF numberKeys key [key ...] ｜ ZUNION numberKeys key [key ...] ：求 n 个 Zset 的交集、差集、并集。 Redis 基础结构及其操作指令总结 基础结构 描述 常用指令 示例 String（字符串） 最基本的数据结构，可以存储字符串、整数或浮点数 SET、GET、INCR、DECR、APPEND、MSET、MGET SET key value，GET key List（列表） 有序集合，允许重复元素，底层为双向链表 LPUSH、RPUSH、LPOP、RPOP、LRANGE LPUSH mylist A B C，LRANGE mylist 0 -1 Set（集合） 无序集合，不允许重复元素 SADD、SREM、SMEMBERS、SISMEMBER SADD myset A B C，SMEMBERS myset Hash（哈希） 类似于对象，存储键值对 HSET、HGET、HGETALL、HDEL HSET user name &quot;Alice&quot;，HGET user name ZSet（有序集合） 具有权重（score）的集合，元素按分数排序 ZADD、ZRANGE、ZREM、ZSCORE ZADD myzset 1 A 2 B，ZRANGE myzset 0 -1 Bitmap（位图） 位级别的存储，用于高效存储和操作二进制数据 SETBIT、GETBIT、BITCOUNT SETBIT mybitmap 10 1，GETBIT mybitmap 10 HyperLogLog 近似去重计数结构，适用于大数据计数 PFADD、PFCOUNT PFADD myhll A B C，PFCOUNT myhll Geo（地理位置） 存储经纬度并计算地理距离 GEOADD、GEODIST、GEORADIUS GEOADD mygeo 120.0 30.0 &quot;place1&quot;，GEODIST mygeo place1 place2 Stream（流） 可持久化的消息队列结构 XADD、XLEN、XREAD XADD mystream * name &quot;Alice&quot;，XREAD COUNT 1 STREAMS mystream 0 这些结构和指令在不同的应用场景中有不同的优势，比如 String 适用于缓存数据，List 适用于消息队列，Set 适用于去重，ZSet 适用于排行榜，Hash 适用于存储对象，Bitmap 适用于用户签到或活跃记录，HyperLogLog 适用于大规模数据去重统计，Geo 适用于地理位置存储，Stream 适用于事件流和消息队列。 java客户端连接redis 使用Jedis 1.导入依赖 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt;&lt;/dependency&gt; 2.建立连接 12345678910111213141516171819202122232425262728293031public class JedisTest { private Jedis jedis; @BeforeEach void setUp(){ //1.建立连接 jedis = new Jedis(&quot;192.168.200.130&quot;,6379); //2.设置密码 jedis.auth(&quot;1234&quot;); //3.选择库 jedis.select(0); } @Test void testString(){ String result = jedis.set(&quot;name&quot;, &quot;小明&quot;); System.out.println(&quot;result= &quot; + result); String name = jedis.get(&quot;name&quot;); System.out.println(&quot;name= &quot;+name); } @AfterEach void tearDown(){ if(jedis!=null){ jedis.close(); } }} 3.jedis连接池 12345678910111213141516171819public class JedisConnectFactory { private static final JedisPool jedisPool; static{ //配置连接池 JedisPoolConfig poolConfig = new JedisPoolConfig(); poolConfig.setMaxTotal(8); poolConfig.setMaxIdle(8); poolConfig.setMinIdle(0); poolConfig.setMaxWait(Duration.ofMillis(1000)); jedisPool = new JedisPool(poolConfig,&quot;192.168.200.130&quot;,6379,1000,&quot;1234&quot;); } public static Jedis getJedis(){ return jedisPool.getResource(); }} 1） JedisConnectionFacotry：工厂设计模式是实际开发中非常常用的一种设计模式，我们可以使用工厂，去降低代的耦合，比如Spring中的Bean的创建，就用到了工厂设计模式 2）静态代码块：随着类的加载而加载，确保只能执行一次，我们在加载当前工厂类的时候，就可以执行static的操作完成对 连接池的初始化 3）最后提供返回连接池中连接的方法. 使用springDataRedis连接 1.导入依赖 12345678910&lt;!--Redis依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--连接池依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt;&lt;/dependency&gt; 2.配置连接信息 123456789101112spring: redis: host: 192.168.200.130 port: 6379 password: 1234 database: 0 lettuce: pool: max-active: 8 #最大连接数 max-idle: 8 #最大空闲连接 min-idle: 0 #最小空闲连接 max-wait: 100 #连接等待时间 3.直接注入RedisTemplate出现的问题 123456789101112131415161718192021222324252627// 自动注入的 `RedisTemplate` 需要加上泛型@Resourceprivate RedisTemplate redisTemplate;@Testpublic void test() { redisTemplate.opsForValue().set(&quot;k1&quot;, &quot;v1&quot;); Map&lt;String, String&gt; map = new HashMap&lt;&gt;(); map.put(&quot;k2&quot;, &quot;v2&quot;); map.put(&quot;k3&quot;, &quot;v3&quot;); map.put(&quot;k4&quot;, &quot;v4&quot;); map.put(&quot;k5&quot;, &quot;v5&quot;); redisTemplate.opsForValue().multiSet(map); redisTemplate.opsForValue().multiGet(Arrays.asList(&quot;k1&quot;, &quot;k2&quot;, &quot;k3&quot;, &quot;k4&quot;)).forEach(System.out::println); // v1 v2 v3 v4 v5}//结果# 在 Redis 中查看通过 RedisTemplate 插入的数据&gt; keys *1) &quot;\\xac\\xed\\x00\\x05t\\x00\\x02k1&quot;2) &quot;\\xac\\xed\\x00\\x05t\\x00\\x02k2&quot;3) &quot;\\xac\\xed\\x00\\x05t\\x00\\x02k3&quot;4) &quot;\\xac\\xed\\x00\\x05t\\x00\\x02k4&quot;5) &quot;\\xac\\xed\\x00\\x05t\\x00\\x02k5&quot;&gt; get &quot;\\xac\\xed\\x00\\x05t\\x00\\x02k1&quot;&quot;\\xac\\xed\\x00\\x05t\\x00\\x02v1&quot; RedisTemplate 存在的问题 通过以上操作可以发现：RedisTemplate 可以将任意类型的数据写入到 Redis 中，在写入前会将其序列化为字节形式存储，底层默认采用 ObjectOutputStream 序列化。 4.因此我们要重写他的序列化工具 导入 jackson-databind 依赖，并编写配置类 RedisTemplateConfig。 12345678910111213141516171819202122@Configurationpublic class RedisTemplateConfig { @Bean public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory) { // 创建 RedisTemplate 对象 RedisTemplate&lt;String, Object&gt; redisTemplate = new RedisTemplate&lt;&gt;(); // 设置连接工厂 redisTemplate.setConnectionFactory(redisConnectionFactory); // 设置序列化工具 GenericJackson2JsonRedisSerializer jsonRedisSerializer = new GenericJackson2JsonRedisSerializer(); // Key 和 HashKey 采用 String 序列化（StringRedisSerializer） redisTemplate.setKeySerializer(RedisSerializer.string()); redisTemplate.setHashKeySerializer(RedisSerializer.string()); // Value 和 HashValue 采用 JSON 序列化（GenericJackson2JsonRedisSerializer） redisTemplate.setValueSerializer(jsonRedisSerializer); redisTemplate.setHashValueSerializer(jsonRedisSerializer); return redisTemplate; }} 12345678910// 自动注入的 `RedisTemplate` 需要加上泛型@Autowiredprivate RedisTemplate&lt;String, Object&gt; redisTemplate;@Testpublic void test() { redisTemplate.opsForValue().set(&quot;k1&quot;, &quot;v1&quot;); redisTemplate.opsForValue().set(&quot;user:1&quot;, new User(&quot;Jack&quot;, 21));} 通过以上的方法能够解决数据序列化时 可读性差、内存占用大 的问题。 但是 JSON 的序列化方式仍然存在一些问题：为了反序列化时知道对象的类型，JSON 序列化器会将类的 class 类型写入 JSON 结果，存入 Redis 中，会带来额外的内存开销。 5.使用StringRedisTemplate 为了节省内存空间，Spring 提供了一个 StringRedisTemplate，它的 key 和 value 的序列化方式默认就是 String，统一使用 String 序列化器。 当需要存储 Java 对象时，手动完成对象的序列化和反序列化。 使用 StringRedisTemplate。 写入数据到 Redis 中，手动将对象序列化为 JSON。 从 Redis 中读取数据，手动将读取到的 JSON 反序列化为对象。 123456789101112131415161718192021222324@Autowiredprivate StringRedisTemplate stringRedisTemplate;private static final ObjectMapper objectMapper = new ObjectMapper();@Testpublic void ttt() throws JsonProcessingException { User user = new User(&quot;Michael&quot;, 27); // 手动序列化 String json = objectMapper.writeValueAsString(user); // 写入数据 stringRedisTemplate.opsForValue().set(&quot;user:1&quot;, json); // 读取数据 String data = stringRedisTemplate.opsForValue().get(&quot;user:1&quot;); // 反序列化 User deserializedUser = objectMapper.readValue(data, User.class); System.out.println(deserializedUser);}//结果{ &quot;username&quot;: &quot;Michael&quot;, &quot;age&quot;: 27}","link":"/posts/redis%E5%9F%BA%E7%A1%80%E7%BB%93%E6%9E%84/"},{"title":"Hexo常用指令大全","text":"Hexo 常用命令速查表 命令 功能 常用参数/示例 初始化 npm install -g hexo-cli 全局安装Hexo命令行工具 hexo init &lt;folder&gt; 初始化博客项目 hexo init myblog npm install 安装依赖包（在项目目录执行） 内容管理 hexo new &quot;标题&quot; 新建文章 hexo new &quot;Hello World&quot; hexo new page &quot;名称&quot; 新建页面 hexo new page &quot;about&quot; hexo publish &lt;filename&gt; 发布草稿 hexo publish draft/untitled.md 生成与预览 hexo generate 生成静态文件（简写hexo g） hexo g --watch（监听文件变化） hexo server 启动本地服务器（简写hexo s） hexo s -p 5000（指定端口） hexo clean 清除缓存和生成文件 常与生成命令组合使用 部署 npm install hexo-deployer-git --save 安装Git部署插件 hexo deploy 部署到服务器（简写hexo d） hexo d --generate（先生成后部署） 组合命令 hexo g -d 生成后立即部署 常用部署组合 hexo s -g 生成后启动服务器 开发调试常用 高级操作 hexo list &lt;type&gt; 列出所有文章/页面等 hexo list post hexo version 查看Hexo版本 hexo --config custom.yml 使用自定义配置文件 多环境配置时使用 典型工作流示例 12345678# 1. 创建新文章hexo new &quot;深入理解Hexo架构&quot;# 2. 本地写作并预览hexo clean &amp;&amp; hexo g &amp;&amp; hexo s# 3. 部署到GitHubhexo clean &amp;&amp; hexo g -d 配置注意要点 部署配置（_config.yml） 1234deploy: type: git repo: https://github.com/用户名/仓库名.git branch: gh-pages 主题配置示例 1theme: icarus # 需先安装主题到themes目录 常用插件推荐 插件 功能 安装命令 hexo-abbrlink 生成永久链接 npm install hexo-abbrlink --save hexo-all-minifier 压缩静态资源 npm install hexo-all-minifier --save hexo-generator-search 添加本地搜索 npm install hexo-generator-search --save 掌握这些命令可提升博客管理效率，建议结合--debug参数排查问题： 1hexo g --debug # 显示详细生成日志 icarus教程:https://ppoffice.github.io/hexo-theme-icarus/categories/Widgets/","link":"/posts/Hexo%E5%B8%B8%E7%94%A8%E6%8C%87%E4%BB%A4%E5%A4%A7%E5%85%A8/"},{"title":"redis缓存的应用","text":"简单的缓存策略 12345678910111213141516171819202122232425262728@Servicepublic class ShopServiceImpl extends ServiceImpl&lt;ShopMapper, Shop&gt; implements IShopService { @Resource private StringRedisTemplate stringRedisTemplate; @Override public Result querygetById(Long id) { //1.从Redis内查询商品缓存 String shopJson = stringRedisTemplate.opsForValue().get(CACHE_SHOP_KEY + id); if(StrUtil.isNotBlank(shopJson)){ //手动反序列化 Shop shop = JSONUtil.toBean(shopJson, Shop.class); return Result.ok(shop); } //2.不存在就根据id查询数据库 Shop shop = getById(id); if(shop==null){ return Result.fail(&quot;商户不存在！&quot;); } //3.数据库数据写入Redis //手动序列化 String shopStr = JSONUtil.toJsonStr(shop); stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY + id,shopStr,CACHE_SHOP_TTL, TimeUnit.MINUTES); return Result.ok(shop); }} 缓存更新策略 缓存更新策略的最佳方案： 低一致性需求：使用Redis自带的内存淘汰机制 高一致性需求：主动更新，超时剔除的方式作为斗地方案 读操作 缓存命中就直接返回 缓存未命中则查询数据库 写操作： 先写数据库，然后再删除缓存 要确保数据库与缓存操作的原子性 操作缓存和数据库时需要考虑的三个问题 删除缓存还是更新缓存？ 每次更新数据库的同时更新缓存：若数据库更新了 100 次，期间没有任何查询请求，此时缓存的更新就是无效操作。 数据库更新就删除缓存：数据库更新后缓存被删除，此时数据库无论更新多少次，缓存都不会做任何操作。直到有查询请求，缓存才会将数据库中的数据写入到缓存中。 如何保证缓存和数据库的操作同时成功或失败？ 单体系统：将缓存与数据库操作放在一个事务。 分布式系统：利用 TCC 等分布式事务方案。 先操作缓存还是先操作数据库？ 先删除缓存，再操作数据库。假设缓存为 10，数据库为 10。（t1、t2、t3 代表三个时刻） t1：线程 1 删除缓存，并更新数据库为 20。t2：线程 2 查询缓存未命中，从数据库中查询并写入缓存。✔️ t1：线程 1 删除缓存。t2：线程 2 查询缓存未命中，从数据库中查询并写入缓存。t3：线程 t1 更新数据库为 20。❌ **先操作数据库，再删除缓存。**假设缓存为 10，数据库为 10。（t1、t2、t3、t4 代表四个时刻） t1：线程 1 更新数据库为 20，删除缓存。t2：线程 2 查询缓存未命中，从数据库中查询并写入缓存。✔️ t1：线程 1 查询缓存未命中，从数据库中查询。t2：线程 2 更新数据库为 20，删除缓存。t3：线程 1 写入缓存。❌（这种方式出现的概率很小，缓存写入的速度很快。更可能出现的情况是：线程 1 写入缓存后，线程 2 更新数据库然后将缓存删除） 123456789101112@Overridepublic Result update(Shop shop) { if(shop.getId()==null){ return Result.fail(&quot;店铺id不能为空!&quot;); } //1.更新数据库 updateById(shop); //2.删除缓存 String key = CACHE_SHOP_KEY + shop.getId(); stringRedisTemplate.delete(key); return Result.ok();} 缓存穿透问题 缓存空对象方案 客户端请求的数据在 Redis 和数据库中都不存在，为了防止不断的请求：将 空值 缓存到 Redis 中并且设置 TTL 时间后，返回给该请求。 缓存中包含过多的 空值，会造成额外的内存消耗。（设置 TTL 可以缓解） 可能造成短期的不一致：第一次请求的数据在 Redis 和数据库中都不存在，缓存空对象后，数据库中新增了该请求对应的数据 1234567891011121314151617181920212223242526272829@Overridepublic CommonResult&lt;Shop&gt; getShopById(Long id) { ThrowUtils.throwIf(id == null, ErrorCode.PARAMS_ERROR); String shopKey = CACHE_SHOP_KEY + id; // 1. 先从 Redis 中查询数据，存在则将其转换为 Java 对象后返回 String shopJsonInRedis = stringRedisTemplate.opsForValue().get(shopKey); if (StringUtils.isNotBlank(shopJsonInRedis)) { return CommonResult.success(JSONUtil.toBean(shopJsonInRedis, Shop.class)); } // 命中空值 if (shopJsonInRedis != null) { throw new BusinessException(ErrorCode.NOT_FOUND_ERROR, &quot;该商铺不存在&quot;); } // 2. 从 Redis 中未查询到数据，则从数据库中查询 Shop shop = this.getById(id); // 若数据中也查询不到，则缓存空值后返回提示信息 if (shop == null) { stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY + id, &quot;&quot;, TTL_TWO, TimeUnit.MINUTES); throw new BusinessException(ErrorCode.NOT_FOUND_ERROR, &quot;该商铺不存在&quot;); } // 3. 将从数据库中查询到的数据存入 Redis 后返回 stringRedisTemplate.opsForValue().set(shopKey, JSONUtil.toJsonStr(shop), TTL_TWO, TimeUnit.HOURS); return CommonResult.success(shop);} 布隆过滤器方案 布隆过滤器（Bloom Filter）：一个很长的二进制数组（初始化值为 0），通过一系列的 Hash 函数判断该数据是否存在。 布隆过滤器的运行速度快、内存占用小，但是存在误判的可能。 存储数据时经过 n 个 hash 函数，计算出 n 个 hash 值，hash 值映射后得到 n 个索引，设置索引处的值为 1。（若当前索引处值已经为 1，则不需要任何操作） 查询数据时也会经过 n 个 hash 函数，计算出 n 个 hash 值，hash 值映射后得到 n 个索引，判断索引处的值是否为 1。 查询 Anthony：经过 hash 算法得到的 hash 值映射后数组下标为 0、2、6，下标对应的值没有全为 1，数组中不存在该元素。 查询 Coco：经过 hash 算法得到的 hash 值映射后数组下标为 0、2、6，下标对应的值都为 1，数组中可能存在该元素。 缓存雪崩问题： 解决方案： 给不同的Key的TTL添加随机值 利用Redis集群提高服务的可用性 给缓存业务添加降级限流策略 给业务添加多级缓存 缓存击穿问题 缓存击穿问题，也叫 热点 Key 问题；就是一个被 高并发访问 并且 缓存中业务较复杂的 Key 突然失效，大量的请求在极短的时间内一起请求这个 Key 并且都未命中，无数的请求访问在瞬间打到数据库上，给数据库带来巨大的冲击。 缓存击穿整体过程： 一个线程查询缓存，未命中，查询数据库并重建缓存（缓存重建业务比较复杂，时间长）。 在这个重建缓存的过程中，大量的请求穿过缓存直接请求数据库并重建缓存，导致性能下降。 解决方案：互斥锁(一致性)、逻辑过期(可用性) 互斥锁方案 synchronized 查询缓存，存在则直接返回。 不存在：执行 synchronized 代码块。 先查缓存，存在则直接返回。（若多个线程执行到同步代码块，某个线程拿到锁查询数据库并重建缓存后，其他拿到锁进来的线程直接查询缓存后返回，避免重复查询数据库并重建缓存） 查询数据库，重建缓存。 12345678910111213141516171819202122232425262728293031323334353637@SneakyThrows@Overridepublic CommonResult&lt;Shop&gt; getShopById(Long id) { ThrowUtils.throwIf(id == null, ErrorCode.PARAMS_ERROR); String shopKey = CACHE_SHOP_KEY + id; // 1. 先从 Redis 中查询数据，存在则将其转换为 Java 对象后返回 String shopJsonInRedis = stringRedisTemplate.opsForValue().get(shopKey); if (StringUtils.isNotBlank(shopJsonInRedis)) { return CommonResult.success(JSONUtil.toBean(shopJsonInRedis, Shop.class)); } // 命中空值 if (shopJsonInRedis != null) { throw new BusinessException(ErrorCode.NOT_FOUND_ERROR, &quot;该商铺不存在&quot;); } // 2. 从 Redis 中未查询到数据，则从数据库中查询。（synchronized） Shop shop = new Shop(); synchronized (ShopServiceImpl.class) { // 3. 再次查询 Redis：若多个线程执行到同步代码块，某个线程拿到锁查询数据库并重建缓存后，其他拿到锁进来的线程直接查询缓存后返回，避免重复查询数据库并重建缓存。 shopJsonInRedis = stringRedisTemplate.opsForValue().get(shopKey); if (StringUtils.isNotBlank(shopJsonInRedis)) { return CommonResult.success(JSONUtil.toBean(shopJsonInRedis, Shop.class)); } // 4. 查询数据库，缓存空值避免缓存穿透，重建缓存。 shop = this.getById(id); if (shop == null) { stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY + id, &quot;&quot;, TTL_TWO, TimeUnit.MINUTES); throw new BusinessException(ErrorCode.NOT_FOUND_ERROR, &quot;该商铺不存在&quot;); } // 模拟缓存重建延迟 Thread.sleep(100); stringRedisTemplate.opsForValue().set(shopKey, JSONUtil.toJsonStr(shop), TTL_TWO, TimeUnit.HOURS); } return CommonResult.success(shop);} 用redis的setnx来充当分布式锁 1234567891011121314/** * 获取互斥锁 */public boolean tryLock(String key) { Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(key, &quot;1&quot;, TTL_TWO, TimeUnit.SECONDS); return Boolean.TRUE.equals(result);}/** * 释放互斥锁 */public void unlock(String key) { stringRedisTemplate.delete(key);} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@SneakyThrows@Overridepublic CommonResult&lt;Shop&gt; getShopById(Long id) { ThrowUtils.throwIf(id == null, ErrorCode.PARAMS_ERROR); String shopKey = CACHE_SHOP_KEY + id; String lockKey = LOCK_SHOP_KEY + id; // 1. 先从 Redis 中查询数据，存在则将其转换为 Java 对象后返回 String shopJsonInRedis = stringRedisTemplate.opsForValue().get(shopKey); if (StringUtils.isNotBlank(shopJsonInRedis)) { return CommonResult.success(JSONUtil.toBean(shopJsonInRedis, Shop.class)); } // 命中空值 if (shopJsonInRedis != null) { throw new BusinessException(ErrorCode.NOT_FOUND_ERROR, &quot;该商铺不存在&quot;); } // 2. 从 Redis 中未查询到数据，尝试获取锁后从数据库中查询。 Shop shop = new Shop(); boolean tryLock = tryLock(lockKey); try { // 2.1 未获取到锁则等待一段时间后重试（通过递归调用重试） if (BooleanUtil.isFalse(tryLock)) { Thread.sleep(50); this.getShopById(id); } // 2.2 获取到锁：查询数据库、缓存重建。 if (tryLock) { // 3. 再次查询 Redis：若多个线程执行到获取锁处，某个线程拿到锁查询数据库并重建缓存后，其他拿到锁进来的线程直接查询缓存后返回，避免重复查询数据库并重建缓存。 shopJsonInRedis = stringRedisTemplate.opsForValue().get(shopKey); if (StringUtils.isNotBlank(shopJsonInRedis)) { return CommonResult.success(JSONUtil.toBean(shopJsonInRedis, Shop.class)); } // 4. 查询数据库，缓存空值避免缓存穿透，重建缓存。 shop = this.getById(id); if (shop == null) { stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY + id, &quot;&quot;, TTL_TWO, TimeUnit.MINUTES); throw new BusinessException(ErrorCode.NOT_FOUND_ERROR, &quot;该商铺不存在&quot;); } // 模拟缓存重建延迟 Thread.sleep(100); stringRedisTemplate.opsForValue().set(shopKey, JSONUtil.toJsonStr(shop), TTL_TWO, TimeUnit.HOURS); } } finally { // 5. 释放锁 unlock(lockKey); } return CommonResult.success(shop);} 逻辑过期方案 无需考虑缓存雪崩（Redis 宕机除外）、缓存穿透问题：缓存何时过期通过代码控制而非 TTL。需要进行数据预热，缓存未命中时直接返回空。 先查询缓存，未命中则直接返回。 命中则判断缓存是否过期，未过期则直接返回。 过期：获取锁。 未获取到锁：直接返回。 获取到锁：开启一个新的线程后直接返回，这个线程负责重建缓存后释放锁。 存储到 Redis 中的 Key 永久有效，过期时间通过代码控制而非 TTL。Redis 存储的数据需要带上一个逻辑过期时间，即 Shop 实体类中需要一个逻辑过期时间属性。新建一个 RedisData，该类包含两个属性 expireTime 和 Data，对原来的代码没有入侵性。 缓存预热（将热点数据提前存储到 Redis 中） 123456@Datapublic class RedisData { private LocalDateTime expireTime; private Object data;} 123456789101112/** * 缓存预热（将热点数据提前存储到 Redis 中） */public void saveHotDataIn2Redis(Long id, Long expireSeconds) { Shop shop = this.getById(id); ThrowUtils.throwIf(shop == null, ErrorCode.NOT_FOUND_ERROR, &quot;该数据不存在&quot;); RedisData redisData = new RedisData(); redisData.setData(shop); redisData.setExpireTime(LocalDateTime.now().plusSeconds(expireSeconds)); stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY + id, JSONUtil.toJsonStr(redisData));} 1234567891011# Redis 中存储的数据会多一个 expireTime 的值{ &quot;expireTime&quot;: 1681660099861, &quot;data&quot;: { &quot;id&quot;: 1, &quot;name&quot;: &quot;101茶餐厅&quot;, &quot;typeId&quot;: 1, ... }} 逻辑过期 1234567891011121314/** * 缓存预热（将热点数据提前存储到 Redis 中） */public void saveHotDataIn2Redis(Long id, Long expireSeconds) throws InterruptedException { Shop shop = this.getById(id); ThrowUtils.throwIf(shop == null, ErrorCode.NOT_FOUND_ERROR, &quot;该数据不存在&quot;); // 模拟缓存重建延迟，让一部分线程先执行完毕，在此期间会短暂的不一致 Thread.sleep(200); RedisData redisData = new RedisData(); redisData.setData(shop); redisData.setExpireTime(LocalDateTime.now().plusSeconds(expireSeconds)); stringRedisTemplate.opsForValue().set(CACHE_SHOP_KEY + id, JSONUtil.toJsonStr(redisData));} 1234567891011121314151617181920212223242526272829303132333435363738394041private static final ExecutorService ES = Executors.newFixedThreadPool(10);@SneakyThrows@Overridepublic CommonResult&lt;Shop&gt; getShopById(Long id) { ThrowUtils.throwIf(id == null, ErrorCode.PARAMS_ERROR); String shopKey = CACHE_SHOP_KEY + id; String lockKey = LOCK_SHOP_KEY + id; // 1. 先从 Redis 中查询数据，未命中则直接返回 String redisDataJson = stringRedisTemplate.opsForValue().get(shopKey); if (StringUtils.isBlank(redisDataJson)) { return CommonResult.success(null); } // 2. 判断是否过期，未过期则直接返回 RedisData redisData = JSONUtil.toBean(redisDataJson, RedisData.class); JSONObject jsonObject = (JSONObject) redisData.getData(); Shop shop = JSONUtil.toBean(jsonObject, Shop.class); LocalDateTime expireTime = redisData.getExpireTime(); if (expireTime.isAfter(LocalDateTime.now())) { return CommonResult.success(shop); } // 3. 未获取到锁直接返回 boolean tryLock = tryLock(lockKey); if (BooleanUtil.isFalse(tryLock)) { return CommonResult.success(shop); } // 4. 获取到锁：开启一个新的线程后返回旧数据。（这个线程负责查询数据库、重建缓存） // 此处无需 DoubleCheck，因为未获取到锁直接返回旧数据，能保证只有一个线程执行到此处 ES.submit(() -&gt; { try { // 查询数据库、重建缓存 this.saveHotDataIn2Redis(id, 3600 * 24L); } catch (Exception e) { log.error(e.getMessage()); } finally { unlock(lockKey); } }); return CommonResult.success(shop);} 总结Redis Cache工具类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219@Component@Slf4jpublic class CacheClient { private static final ExecutorService ES = Executors.newFixedThreadPool(10); private final StringRedisTemplate stringRedisTemplate; public CacheClient(StringRedisTemplate stringRedisTemplate) { this.stringRedisTemplate = stringRedisTemplate; } /** * 获取锁 */ public boolean tryLock(String key) { Boolean result = stringRedisTemplate.opsForValue().setIfAbsent(key, &quot;1&quot;, TTL_TWO, TimeUnit.SECONDS); return BooleanUtil.isTrue(result); } /** * 释放锁 */ public void unlock(String key) { stringRedisTemplate.delete(key); } /** * 数据预热（将热点数据提前存储到 Redis 中） * * @param key 预热数据的 Key * @param value 预热数据的 Value * @param expireTime 逻辑过期时间 * @param timeUnit 时间单位 */ public void dataWarmUp(String key, Object value, Long expireTime, TimeUnit timeUnit) { RedisData redisData = new RedisData(); redisData.setData(value); redisData.setExpireTime(LocalDateTime.now().plusSeconds(timeUnit.toSeconds(expireTime))); stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(redisData)); } /** * 将 Java 对象序列化为 JSON 存储到 Redis 中并且设置 TTL 过期时间 * * @param key String 类型的键 * @param value 序列化为 JSON 的值 * @param time TTL 过期时间 * @param timeUnit 时间单位 */ public void set(String key, Object value, Long time, TimeUnit timeUnit) { stringRedisTemplate.opsForValue().set(key, JSONUtil.toJsonStr(value), time, timeUnit); } /** * 解决缓存穿透问（缓存空值） * * @param keyPrefix Key 前缀 * @param id id * @param type 实体类型 * @param function 有参有返回值的函数 * @param time TTL 过期时间 * @param timeUnit 时间单位 * @param &lt;R&gt; 实体类型 * @param &lt;ID&gt; id 类型 * @return 设置某个实体类的缓存，并解决缓存穿透问题 */ public &lt;R, ID&gt; R setWithCachePenetration(String keyPrefix, ID id, Class&lt;R&gt; type, Function&lt;ID, R&gt; function, Long time, TimeUnit timeUnit) { String key = keyPrefix + id; // 1. 先从 Redis 中查询数据，存在则将其转换为 Java 对象后返回 String jsonStr = stringRedisTemplate.opsForValue().get(key); if (StringUtils.isNotBlank(jsonStr)) { return JSONUtil.toBean(jsonStr, type); } // 命中空值 if (jsonStr != null) { throw new BusinessException(ErrorCode.NOT_FOUND_ERROR); } // 2. 从 Redis 中未查询到数据，则从数据库中查询 R result = function.apply(id); // 若数据中也查询不到，则缓存空值后返回提示信息 if (result == null) { stringRedisTemplate.opsForValue().set(key, &quot;&quot;, TTL_TWO, TimeUnit.MINUTES); throw new BusinessException(ErrorCode.NOT_FOUND_ERROR); } // 3. 将从数据库中查询到的数据存入 Redis 后返回 this.set(key, result, time, timeUnit); return result; } /** * 解决缓存击穿问题（synchronized） */ public &lt;R, ID&gt; R setWithCacheBreakdown4Synchronized(String keyPrefix, ID id, Class&lt;R&gt; type, Function&lt;ID, R&gt; function, Long time, TimeUnit timeUnit) { String key = keyPrefix + id; // 1. 先从 Redis 中查询数据，存在则将其转换为 Java 对象后返回 String jsonStr = stringRedisTemplate.opsForValue().get(key); if (StringUtils.isNotBlank(jsonStr)) { return JSONUtil.toBean(jsonStr, type); } // 命中空值 if (jsonStr != null) { throw new BusinessException(ErrorCode.NOT_FOUND_ERROR); } // 2. 从 Redis 中未查询到数据，则从数据库中查询。（synchronized） R result = null; synchronized (CacheClient.class) { // 3. 再次查询 Redis：若多个线程执行到同步代码块，某个线程拿到锁查询数据库并重建缓存后，其他拿到锁进来的线程直接查询缓存后返回，避免重复查询数据库并重建缓存。 jsonStr = stringRedisTemplate.opsForValue().get(key); if (StringUtils.isNotBlank(jsonStr)) { return JSONUtil.toBean(jsonStr, type); } // 4. 查询数据库、缓存空值避免缓存穿透、重建缓存。 result = function.apply(id); if (result == null) { stringRedisTemplate.opsForValue().set(key, &quot;&quot;, TTL_TWO, TimeUnit.MINUTES); throw new BusinessException(ErrorCode.NOT_FOUND_ERROR); } this.set(key, result, time, timeUnit); } return result; } /** * 解决缓存击穿问题（setnx） */ public &lt;R, ID&gt; R setWithCacheBreakdown4SetNx(String keyPrefix, ID id, Class&lt;R&gt; type, Function&lt;ID, R&gt; function, Long time, TimeUnit timeUnit) { String key = keyPrefix + id; String lockKey = LOCK_SHOP_KEY + id; // 1. 先从 Redis 中查询数据，存在则将其转换为 Java 对象后返回 String jsonStr = stringRedisTemplate.opsForValue().get(key); if (StringUtils.isNotBlank(jsonStr)) { return JSONUtil.toBean(jsonStr, type); } // 命中空值 if (jsonStr != null) { throw new BusinessException(ErrorCode.NOT_FOUND_ERROR); } // 2. 从 Redis 中未查询到数据，尝试获取锁后从数据库中查询。 R result = null; boolean tryLock = tryLock(lockKey); try { // 2.1 未获取到锁则等待一段时间后重试（通过递归调用重试） if (BooleanUtil.isFalse(tryLock)) { Thread.sleep(50); this.setWithCacheBreakdown4SetNx(keyPrefix, id, type, function, time, timeUnit); } // 2.2 获取到锁：查询数据库、缓存重建。 if (tryLock) { // 3. 再次查询 Redis：若多个线程执行到同步代码块，某个线程拿到锁查询数据库并重建缓存后，其他拿到锁进来的线程直接查询缓存后返回，避免重复查询数据库并重建缓存。 jsonStr = stringRedisTemplate.opsForValue().get(key); if (StringUtils.isNotBlank(jsonStr)) { return JSONUtil.toBean(jsonStr, type); } // 4. 查询数据库、缓存空值避免缓存穿透、重建缓存。 result = function.apply(id); if (result == null) { stringRedisTemplate.opsForValue().set(key, &quot;&quot;, TTL_TWO, TimeUnit.MINUTES); throw new BusinessException(ErrorCode.NOT_FOUND_ERROR); } this.set(key, result, time, timeUnit); } } catch (Exception e) { log.error(e.getMessage()); } finally { unlock(lockKey); } return result; } /** * 解决缓存击穿问题（逻辑过期时间） */ public &lt;R, ID&gt; R setWithCacheBreakdown4LogicalExpiration(String keyPrefix, ID id, Class&lt;R&gt; type, Function&lt;ID, R&gt; function, Long time, TimeUnit timeUnit) { String key = keyPrefix + id; String lockKey = LOCK_SHOP_KEY + id; // 1. 先从 Redis 中查询数据，未命中则直接返回 String jsonStr = stringRedisTemplate.opsForValue().get(key); if (StringUtils.isBlank(jsonStr)) { return null; } // 2. 判断是否过期，未过期则直接返回 RedisData redisData = JSONUtil.toBean(jsonStr, RedisData.class); JSONObject jsonObject = JSONUtil.parseObj(redisData.getData()); R result = JSONUtil.toBean(jsonObject, type); LocalDateTime expireTime = redisData.getExpireTime(); if (expireTime.isAfter(LocalDateTime.now())) { return result; } // 3. 未获取到锁直接返回 boolean tryLock = tryLock(lockKey); if (BooleanUtil.isFalse(tryLock)) { return result; } // 4. 获取到锁：开启一个新的线程后返回旧数据。（这个线程负责查询数据库、重建缓存） // 此处无需 DoubleCheck，因为未获取到锁直接返回旧数据，能保证只有一个线程执行到此处 ES.submit(() -&gt; { try { this.dataWarmUp(key, function.apply(id), time, timeUnit); } finally { unlock(lockKey); } }); return result; }}","link":"/posts/redis%E7%BC%93%E5%AD%98%E7%9A%84%E5%BA%94%E7%94%A8/"},{"title":"redis解决常见的秒杀问题","text":"秒杀问题 每个店铺都可以发布优惠券，保存到 tb_voucher 表中；当用户抢购时，生成订单并保存到 tb_voucher_order 表中。 订单表如果使用数据库自增 ID，会存在以下问题： ID 的规律太明显，容易暴露信息。 单表数据量的限制，订单过多时单表很难存储得下。数据量过大后需要拆库拆表，但拆分表了之后，各表从逻辑上是同一张表，所以 id 不能一样， 于是需要保证 ID 的唯一性。 全局唯一ID 全局唯一 ID 的特点 唯一性：Redis 独立于数据库之外，不论有多少个数据库、多少张表，访问 Redis 获取到的 ID 可以保证唯一。 高可用：Redis 高可用（集群等方案）。 高性能：Redis 速度很快。 递增性：例如 String 的 INCR 命令，可以保证递增。 安全性：为了增加 ID 的安全性，在使用 Redis 自增数值的基础上，在拼接一些其他信息。 全局唯一 ID 的组成（存储数值类型占用空间更小，使用 long 存储，8 byte，64 bit） 符号位：1 bit，永远为 0，代表 ID 是正数。 时间戳：31 bit，以秒为单位，可以使用 69 年。 序列号：32 bit，当前时间戳对应的数量，也就是每秒可以对应 2^32 个不同的 ID。 Redis ID 自增策略：通过设置每天存入一个 Key，方便统计订单数量；ID 构造为 时间戳 + 计数器。 123456789101112131415161718192021222324252627@Componentpublic class RedisIdWorker { /** * 指定时间戳（2023年1月1日 0:0:00） LocalDateTime.of(2023, 1, 1, 0, 0, 0).toEpochSecond(ZoneOffset.UTC) */ private static final long BEGIN_TIMESTAMP_2023 = 1672531200L; /** * 序列号位数 */ private static final int BIT_COUNT = 32; private final StringRedisTemplate stringRedisTemplate; public RedisIdWorker(StringRedisTemplate stringRedisTemplate) { this.stringRedisTemplate = stringRedisTemplate; } public long nextId(String keyPrefix) { // 1. 时间戳 long timestamp = LocalDateTime.now().toEpochSecond(ZoneOffset.UTC) - BEGIN_TIMESTAMP_2023; // 2. 生成序列号：自增 1，Key 不存在会自动创建一个 Key。（存储到 Redis 中的 Key 为 keyPrefix:date，Value 为自增的数量） Long serialNumber = stringRedisTemplate.opsForValue().increment(keyPrefix + &quot;:&quot; + DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;).format(LocalDate.now())); // 3. 时间戳左移 32 位，序列号与右边的 32 个 0 进行与运算 return timestamp &lt;&lt; BIT_COUNT | serialNumber; }} 测试(300个线程生成共3w个id) 1234567891011121314151617181920212223242526@Resourceprivate RedisIdWorker redisIdWorker;public static final ExecutorService ES = Executors.newFixedThreadPool(500);@Testvoid testGloballyUniqueID() throws Exception { // 程序是异步的，分线程全部走完之后主线程再走，使用 CountDownLatch；否则异步程序没有执行完时主线程就已经执行完了 CountDownLatch latch = new CountDownLatch(300); Runnable task = () -&gt; { for (int i = 0; i &lt; 100; i++) { long globallyUniqueID = redisIdWorker.nextId(&quot;sun&quot;); System.out.println(&quot;globallyUniqueID = &quot; + globallyUniqueID); } latch.countDown(); }; long begin = System.currentTimeMillis(); for (int i = 0; i &lt; 300; i++) { ES.submit(task); } latch.await(); long end = System.currentTimeMillis(); System.out.println(&quot;Execution Time: &quot; + (end - begin));} 添加优惠卷 格式类似这种逻辑太简单了略 123456789101112{ &quot;shopId&quot;:1, &quot;title&quot;:&quot;100元代金券&quot;, &quot;subTitle&quot;:&quot;周一至周五均可使用&quot;, &quot;rules&quot;:&quot;全场通用\\n无需预约\\n可无限叠加\\n不兑现、不找零\\n仅限堂食&quot;, &quot;payValue&quot;:8000, &quot;actualValue&quot;:10000, &quot;type&quot;:1, &quot;stock&quot;:100, &quot;beginTime&quot;:&quot;2022-11-13T10:09:17&quot;, &quot;endTime&quot;:&quot;2022-11-13T22:10:17&quot;} 秒杀下单功能 1234567891011121314151617181920212223242526272829303132333435363738394041@Override@Transactionalpublic Result seckillVoucher(Long voucherId) { //1.查询优惠卷 SeckillVoucher voucher = seckillVoucherService.getById(voucherId); //2.判断秒杀是否开始，是否结束 if (voucher.getBeginTime().isAfter(LocalDateTime.now())) { return Result.fail(&quot;秒杀尚未开始!&quot;); } if(voucher.getEndTime().isBefore(LocalDateTime.now())){ return Result.fail(&quot;秒杀已结束!&quot;); } //3.判断库存是否充足 if(voucher.getStock()&lt;=0){ return Result.fail(&quot;优惠券库存不足!&quot;); } //4.扣减库存 boolean success = seckillVoucherService.update() .setSql(&quot;stock = stock -1&quot;) .eq(&quot;voucher_id&quot;, voucherId).update(); //5.创建订单 if(!success){ return Result.fail(&quot;优惠券库存不足!&quot;); } //6.返回订单id VoucherOrder voucherOrder = new VoucherOrder(); //6.1订单id long orderId = redisIdWorker.nextId(&quot;order&quot;); voucherOrder.setId(orderId); //6.2用户id Long userId = UserHolder.getUser().getId(); voucherOrder.setUserId(userId); //6.3代金券id voucherOrder.setVoucherId(voucherId); //7.订单写入数据库 save(voucherOrder); //8.返回订单Id return Result.ok(orderId);} 超卖问题 假设库存为 1，有线程1、2、3，时刻 t1、t2、t3、t4。 t1：线程1 查询库存，库存为 1； t2：线程2、线程 3 查询库存，库存为 1； t3：线程1 下单，库存扣减为 0。 t4：线程2 和 线程3 下单，库存扣减为 -2。 具体图示: 解决超卖问题 悲观锁 太简单了直接加锁保证操作数据是原子操作要串行执行 乐观锁 版本号法: 一般是在数据库表中加上一个 version 字段表示 数据被修改的次数。数据被修改时 version 值加 1。 线程 A 读取数据，同时读取到 version 值。 提交更新时，若刚才读到的 version 值未发生变化：则提交更新并且 version 值加 1。 提交更新时，若刚才读到的 version 值发生了变化：放弃更新，并通过报错、自旋重试等方式进行下一步处理。 CAS法(简单来说就是直接拿库存当版本号): CAS 操作需要输入两个数值，一个旧值（操作前的值）和一个新值，操作时先比较下在旧值有没有发生变化，若未发生变化才交换成新值，发生了变化则不交换。 CAS 是原子操作，多线程并发使用 CAS 更新数据时，可以不使用锁。原子操作是最小的不可拆分的操作，操作一旦开始，不能被打断，直到操作完成。也就是多个线程对同一块内存的操作是串行的。 一人一单问题 一人一单逻辑: 发送下单请求，提交优惠券 ID。 下单前需要判断：秒杀是否开始或结束、库存是否充足。 库存充足：根据优惠券 ID 和用户 ID 查询订单，判断该用户是否购买过该优惠券。 该用户对该优惠券的订单不存在时，扣减库存、创建订单、返回订单 ID。 解决并发安全问题 单人下单（一个用户），高并发的情况下：该用户的 10 个线程同时执行到 查询该用户 ID 和秒杀券对应的订单数量，10 个线程查询到的值都为 0，即未下单。于是会出现一个用户下 10 单的情况。 **此处仍需加锁，乐观锁适合更新操作，插入操作需要选择悲观锁。**若直接在方法上添加 synchronized 关键字，会让锁的范围（粒度）过大，导致性能较差。因此，采用 一个用户一把锁 的方式。 问题：能否用乐观锁执行？ 不能，原因是乐观锁只能操作(修改)单个变量，而创建订单需要操作数据库(难以跟踪状态) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546@Overridepublic CommonResult&lt;Long&gt; seckillVoucher(Long voucherId) { // 判断秒杀是否开始或结束、库存是否充足。 SeckillVoucher seckillVoucher = seckillVoucherService.getById(voucherId); ThrowUtils.throwIf(seckillVoucher == null, ErrorCode.NOT_FOUND_ERROR); LocalDateTime now = LocalDateTime.now(); ThrowUtils.throwIf(now.isBefore(seckillVoucher.getBeginTime()), ErrorCode.OPERATION_ERROR, &quot;秒杀尚未开始&quot;); ThrowUtils.throwIf(now.isAfter(seckillVoucher.getEndTime()), ErrorCode.OPERATION_ERROR, &quot;秒杀已经结束&quot;); ThrowUtils.throwIf(seckillVoucher.getStock() &lt; 1, ErrorCode.OPERATION_ERROR, &quot;库存不足&quot;); // 下单 return this.createVoucherOrder(voucherId);}/** * 下单（超卖 - CAS、一人一单 - synchronized） */@Override@Transactionalpublic CommonResult&lt;Long&gt; createVoucherOrder(Long voucherId) { // 1. 判断当前用户是否下过单 Long userId = UserHolder.getUser().getId(); Integer count = this.lambdaQuery() .eq(VoucherOrder::getVoucherId, voucherId) .eq(VoucherOrder::getUserId, userId) .count(); ThrowUtils.throwIf(count &gt; 0, ErrorCode.OPERATION_ERROR, &quot;禁止重复下单&quot;); // 2. 扣减库存 boolean result = seckillVoucherService.update() .setSql(&quot;stock = stock - 1&quot;) .eq(&quot;voucher_id&quot;, voucherId) .gt(&quot;stock&quot;, 0) .update(); ThrowUtils.throwIf(!result, ErrorCode.OPERATION_ERROR, &quot;下单失败&quot;); // 3. 下单 VoucherOrder voucherOrder = new VoucherOrder(); voucherOrder.setUserId(userId); voucherOrder.setId(redisIdWorker.nextId(&quot;seckillVoucherOrder&quot;)); voucherOrder.setVoucherId(voucherId); result = this.save(voucherOrder); ThrowUtils.throwIf(!result, ErrorCode.OPERATION_ERROR, &quot;下单失败&quot;); return CommonResult.success(voucherOrder.getId());} 集群环境下的并发问题 分布式锁-原理 不去使用jvm内部的锁监视器，我们要在外部开一个锁监视器，让它监视所有的线程 常见的分布式锁 MySQL：MySQL 本身带有锁机制，但是由于 MySQL 性能一般，所以采用分布式锁的情况下，使用 MySQL 作为分布式锁比较少见。 Redis：Redis 作为分布式锁比较常见，利用 setnx 方法，如果 Key 插入成功，则表示获取到锁，插入失败则表示无法获取到锁。 Zookeeper：Zookeeper 也是企业级开发中比较好的一个实现分布式锁的方案。 MySQL Redis Zookeeper 互斥 利用 MySQL 本身的互斥锁机制 利用 setnx 互斥命令 利用节点的唯一性和有序性 高可用 好 好 好 高性能 一般 好 一般 安全性 断开链接，自动释放锁 利用锁超时时间，到期释放 临时节点，断开链接自动释放 12345# 添加锁（NX 互斥、EX 设置 TTL 时间）SET lock thread1 NX EX 10# 手动释放锁DEL lock 123456789101112131415161718192021222324252627282930313233343536373839public interface DistributedLock { /** * 获取锁（只有一个线程能够获取到锁） * @param timeout 锁的超时时间，过期后自动释放 * @return true 代表获取锁成功；false 代表获取锁失败 */ boolean tryLock(long timeout); /** * 释放锁 */ void unlock();}public class SimpleDistributedLock4Redis implements DistributedLock { private static final String KEY_PREFIX = &quot;lock:&quot;; private final String name; private final StringRedisTemplate stringRedisTemplate; public SimpleDistributedLockBased4Redis(String name, StringRedisTemplate stringRedisTemplate) { this.name = name; this.stringRedisTemplate = stringRedisTemplate; } @Override public boolean tryLock(long timeout) { String threadId = Thread.currentThread().getId().toString(); Boolean result = stringRedisTemplate.opsForValue() .setIfAbsent(KEY_PREFIX + name, threadId, timeout, TimeUnit.SECONDS); // result 是 Boolean 类型，直接返回存在自动拆箱，为防止空指针不直接返回 return Boolean.TRUE.equals(result); } @Override public void unlock() { stringRedisTemplate.delete(KEY_PREFIX + name); }} 1234567891011121314151617181920/** * VERSION3.0 - 秒杀下单优惠券（通过分布式锁解决一人一单问题） */@Overridepublic CommonResult&lt;Long&gt; seckillVoucher(Long voucherId) { // 判断秒杀是否开始或结束、库存是否充足。 ... // 下单 SimpleDistributedLock4Redis lock = new SimpleDistributedLock4Redis(&quot;order:&quot; + UserHolder.getUser().getId(), stringRedisTemplate); boolean tryLock = lock.tryLock(TTL_TWO); ThrowUtils.throwIf(!tryLock, ErrorCode.OPERATION_ERROR, &quot;禁止重复下单&quot;); try { VoucherOrderService voucherOrderService = (VoucherOrderService) AopContext.currentProxy(); return voucherOrderService.createVoucherOrder(voucherId); } finally { lock.unlock(); }} 误删问题 123456789101112# 线程 1 获取到锁后执行业务，碰到了业务阻塞。setnx lock:order:1 thread01# 业务阻塞的时间超过了该锁的 TTL 时间，触发锁的超时释放。超时释放后，线程 2 获取到锁并执行业务。setnx lock:order:1 thread02# 线程 2 执行业务的过程中，线程 1 的业务执行完毕并且释放锁，但是释放的是线程 2 获取到的锁。（线程 2：你 TM 放我锁是吧！）del lock:order:1# 线程 3 获取到锁（此时线程 2 和 3 并行执行业务）setnx lock:order:1 thread03 解决方案：在线程释放锁时，判断当前这把锁是否属于自己，如果不属于自己，就不会进行锁的释放（删除）。 123456789101112# 线程 1 获取到锁后执行业务，碰到了业务阻塞。setnx lock:order:1 thread01# 业务阻塞的时间超过了该锁的 TTL 时间，触发锁的超时释放。超时释放后，线程 2 获取到锁并执行业务。setnx lock:order:1 thread02# 线程 2 执行业务的过程中，线程 1 的业务执行完毕并且释放锁。但是线程 1 需要判断这把锁是否属于自己，不属于自己就不会释放锁。# 于是线程 2 一直持有这把锁直到业务执行结束后才会释放，并且在释放时也需要判断当前要释放的锁是否属于自己。del lock:order:1# 线程 3 获取到锁并执行业务setnx lock:order:1 thread03 基于 Redis 的分布式锁的实现（解决误删问题） 相较于最开始分布式锁的实现，只需要增加一个功能：释放锁时需要判断当前锁是否属于自己。（而集群环境下不同 JVM 中的线程 ID 可能相同，增加一个 UUID 区分不同 JVM） 因此通过分布式锁存入 Redis 中的线程标识包括：UUID (服务器id)+ 线程 ID(线程id)。UUID 用于区分不同服务器中线程 ID 相同的线程，线程 ID 用于区分相同服务器的不同线程。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class SimpleDistributedLockBasedOnRedis implements DistributedLock { private String name; private StringRedisTemplate stringRedisTemplate; public SimpleDistributedLockBasedOnRedis(String name, StringRedisTemplate stringRedisTemplate) { this.name = name; this.stringRedisTemplate = stringRedisTemplate; } private static final String KEY_PREFIX = &quot;lock:&quot;; // ID_PREFIX 在当前 JVM 中是不变的，主要用于区分不同 JVM private static final String ID_PREFIX = UUID.randomUUID().toString(true) + &quot;-&quot;; /** * 获取锁 */ @Override public boolean tryLock(long timeoutSeconds) { // UUID 用于区分不同服务器中线程 ID 相同的线程；线程 ID 用于区分同一个服务器中的线程。 String threadIdentifier = ID_PREFIX + Thread.currentThread().getId(); Boolean isSucceeded = stringRedisTemplate.opsForValue() .setIfAbsent(KEY_PREFIX + name, threadIdentifier, timeoutSeconds, TimeUnit.SECONDS); return Boolean.TRUE.equals(isSucceeded); } /** * 释放锁（释放锁前通过判断 Redis 中的线程标识与当前线程的线程标识是否一致，解决误删问题） */ @Override public void unlock() { // UUID 用于区分不同服务器中线程 ID 相同的线程；线程 ID 用于区分同一个服务器中的线程。 String threadIdentifier = THREAD_PREFIX + Thread.currentThread().getId(); String threadIdentifierFromRedis = stringRedisTemplate.opsForValue().get(KEY_PREFIX + name); // 比较 Redis 中的线程标识与当前的线程标识是否一致 if (!StrUtil.equals(threadIdentifier, threadIdentifierFromRedis)) { throw new BusinessException(ErrorCode.OPERATION_ERROR, &quot;释放锁失败&quot;); } // 释放锁标识 stringRedisTemplate.delete(KEY_PREFIX + name); }} 用Lua脚本解决原子性问题 分布式锁的原子性问题 线程 1 获取到锁并执行完业务，判断锁标识一致后释放锁，释放锁的过程中阻塞，导致锁没有释放成功，并且阻塞的时间超过了锁的 TTL 释放，导致锁自动释放。 此时线程 2 获取到锁，执行业务；在线程 2 执行业务的过程中，线程 1 完成释放锁操作。 之后，线程 3 获取到锁，执行业务，又一次导致此时有两个线程同时在并行执行业务。 因此，需要保证 unlock() 方法的原子性，即判断线程标识的一致性和释放锁这两个操作的原子性。 Redis 提供了 Lua 脚本功能，在一个脚本中编写多条 Redis 命令，确保 Redis 多条命令执行时的原子性。 unlock操作 12345678910111213141516private static final DefaultRedisScript&lt;Long&gt; UNLOCK_SCRIPT;static{//写成静态代码块，类加载就可以完成初始定义，就不用每次释放锁都去加载这个，性能提高咯 UNLOCK_SCRIPT = new DefaultRedisScript&lt;&gt;(); UNLOCK_SCRIPT.setLocation(new ClassPathResource(&quot;unlock.lua&quot;));//设置脚本位置 UNLOCK_SCRIPT.setResultType(Long.class);} public void unlock(){ //调用lua脚本 stringRedisTemplate.execute( UNLOCK_SCRIPT, Collections.singletonList(KEY_PREFIX + name), ID_PREFIX + Thread.currentThread().getId() ); } Lua脚本 12345678-- 锁的key-- local key = KEYS[1]-- 当前线程标识-- local threadId = ARGV[1]-- 获取锁中的线程标识if(redis.call('get',KEYS[1]) == ARGV[1]) then return redis.call('del',KEYS[1])end return 0","link":"/posts/redis%E8%A7%A3%E5%86%B3%E5%B8%B8%E8%A7%81%E7%9A%84%E7%A7%92%E6%9D%80%E9%97%AE%E9%A2%98/"},{"title":"使用lua优化一人一单问题","text":"集群环境下的并发问题 分布式锁-原理 不去使用jvm内部的锁监视器，我们要在外部开一个锁监视器，让它监视所有的线程 Lua解决！ 解决这个问题主要是让一个用户不能同时创建两个订单(在缓存创建前) lua可以在保证原子性redis执行的原子性，所以咱可以用他解决一人一单引发的并发问题无需加锁 lua代码逻辑 12345678910111213141516171819202122232425262728293031-- 参数列表-- 优惠卷idlocal voucherId = ARGV[1]-- 用户idlocal userId = ARGV[2]-- 数据key-- 库存keylocal stockKey = 'seckill:stock:' .. voucherId-- 订单keylocal orderKey = 'seckill:order:' .. voucherIdprint(stockKey)print(orderKey)-- 脚本业务-- 检查库存是否充足if(tonumber(redis.call('get', stockKey)) &lt;= 0) then return 1end-- 检查用户是否已下单if(redis.call('sismember', orderKey, userId) == 1) then return 2end-- 扣库存redis.call('incrby', stockKey, -1)-- 下单保存用户redis.call('sadd', orderKey, userId)return 0 java调用代码逻辑 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051private static final DefaultRedisScript&lt;Long&gt; SECKILL_SCRIPT; static { SECKILL_SCRIPT = new DefaultRedisScript&lt;&gt;(); SECKILL_SCRIPT.setLocation(new ClassPathResource(&quot;seckill.lua&quot;)); SECKILL_SCRIPT.setResultType(Long.class); } private IVoucherOrderService proxy; @Override @Transactional public Result seckillVoucher(Long voucherId) { //获取用户 Long userId = UserHolder.getUser().getId(); System.out.println(&quot;userId = &quot; + userId); System.out.println(&quot;voucherId = &quot; + voucherId); //执行lua脚本 Long result = stringRedisTemplate.execute( SECKILL_SCRIPT, Collections.emptyList(), voucherId.toString(), userId.toString() ); //判断结果是否为零 assert result != null; int r = result.intValue(); if(r!=0){ return switch (r) { case 1 -&gt; Result.fail(&quot;库存不足&quot;); case 2 -&gt; Result.fail(&quot;不能重复下单&quot;); default -&gt; Result.fail(&quot;系统错误&quot;); }; } long orderId = redisIdWorker.nextId(&quot;order&quot;); // 保存阻塞队列 VoucherOrder voucherOrder = new VoucherOrder(); //订单id voucherOrder.setId(orderId); //用户id voucherOrder.setUserId(userId); //代金券id voucherOrder.setVoucherId(voucherId); //加入阻塞队列 orderTasks.add(voucherOrder); proxy = (IVoucherOrderService) AopContext.currentProxy(); //不为0 //为0 有购买资格 把下单信息保存到阻塞队列 //返回订单id return Result.ok(orderId); }","link":"/posts/%E4%BD%BF%E7%94%A8lua%E4%BC%98%E5%8C%96%E4%B8%80%E4%BA%BA%E4%B8%80%E5%8D%95%E9%97%AE%E9%A2%98/"},{"title":"redis读写一致问题","text":"Redis读写一致问题 条件: 数据库此时的数据为10,redis此时的数据也为10 业务流程: 操作数据库使得数据库的数据为20，删除redis里面的数据保证读写一致 先删缓存，再操作数据库 出现读写不一致情况: 线程1(业务) 线程2(并发线程) 删除缓存 查询缓存，没有命中，查询数据库(数据库查到为10，下一步将10写入redis) 将10写入缓存 更新数据库，将数据库中的数据改为20 最终情况 redis里面的数据 数据库里面的数据 10 20 出现数据不一致情况 先操作数据库，再删除缓存 线程1(并发线程) 线程2(业务线程) 查询缓存未命中，查询数据库(下一步:将缓存更新为10) 更新数据库 v=20 删除缓存 写入缓存数据10 最终情况: redis数据 数据库数据 10 20 两个方法选择原则 适用策略 典型场景 是否推荐使用延迟双删 先删缓存 → 后更新数据库 高一致性业务（余额、库存） ✅ 一定要延迟双删！ 先更新数据库 → 后删缓存 低一致性业务（资料、文章内容） ❌ 可以不用延迟双删 解决方案:双写一致性 读操作没啥问题按照老流程 延时双删 问题 答案 先删缓存还是先改数据库？ 先删缓存！ 避免并发写入旧值 为什么删两次？ 防止“改库之后，又有人写了旧值到缓存” 为什么要延迟删？ 给并发线程一个“写入脏缓存”的机会，然后再清理掉它 缺点: 问题点 延迟双删解决得了么？ 推荐改进方式 并发窗口写入脏缓存 ❌ 只能删最后一个 分布式锁 + 双删 / MQ 延迟时间难控制 ❌ 不可预测 MQ 或 Canal 机制更精准 异步删除失败风险 ❌ 会丢失删除 使用可靠任务队列 / Redis 持久化 操作复杂、代码维护困难 ❌ 容易遗漏 key 封装中间件、使用 AOP统一处理 给他加锁 读写都加锁 如图，程序运行串行化，性能低 引入共享锁和排他锁机制 共享锁：读锁readLock，加锁之后，其他线程可以共享读操作 排他锁：独占锁writeLock也叫，加锁之后，阻塞其他线程读写操作 代码Demo 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import org.redisson.api.RReadWriteLock;import org.redisson.api.RedissonClient;import org.redisson.api.RLock;import java.util.concurrent.TimeUnit;public class UserService { private final RedissonClient redissonClient; private final RedisService redisService; // 你封装的 Redis 工具类 private final UserRepository userRepository; // 你操作数据库的类 public UserService(RedissonClient redissonClient, RedisService redisService, UserRepository userRepository) { this.redissonClient = redissonClient; this.redisService = redisService; this.userRepository = userRepository; } // 读操作：加“读锁” public User getUserById(Long userId) { String key = &quot;user:&quot; + userId; String lockKey = &quot;lock:user:&quot; + userId; RReadWriteLock rwLock = redissonClient.getReadWriteLock(lockKey); RLock readLock = rwLock.readLock(); try { readLock.lock(5, TimeUnit.SECONDS); // 加读锁，防止同时写入 User user = redisService.get(key); // 先查缓存 if (user != null) { return user; } // 缓存未命中 → 查数据库并回写缓存 user = userRepository.findById(userId); if (user != null) { redisService.set(key, user, 10, TimeUnit.MINUTES); } return user; } finally { readLock.unlock(); // 释放读锁 } } // 写操作：加“写锁” public void updateUser(User user) { Long userId = user.getId(); String key = &quot;user:&quot; + userId; String lockKey = &quot;lock:user:&quot; + userId; RReadWriteLock rwLock = redissonClient.getReadWriteLock(lockKey); RLock writeLock = rwLock.writeLock(); try { writeLock.lock(10, TimeUnit.SECONDS); // 加写锁，防止并发读/写 redisService.del(key); // 删除缓存（第一次） userRepository.save(user); // 更新数据库 // 第二次删除可延迟做（避免并发写入旧值） Thread.sleep(500); // 模拟延迟 redisService.del(key); // 延迟删除（第二次） } catch (InterruptedException e) { e.printStackTrace(); } finally { writeLock.unlock(); // 释放写锁 } }} 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import org.redisson.api.RReadWriteLock;import org.redisson.api.RedissonClient;import org.redisson.api.RLock;import java.util.concurrent.TimeUnit;public class UserService { private final RedissonClient redissonClient; private final RedisService redisService; // 你封装的 Redis 工具类 private final UserRepository userRepository; // 你操作数据库的类 public UserService(RedissonClient redissonClient, RedisService redisService, UserRepository userRepository) { this.redissonClient = redissonClient; this.redisService = redisService; this.userRepository = userRepository; } // 读操作：加“读锁” public User getUserById(Long userId) { String key = &quot;user:&quot; + userId; String lockKey = &quot;lock:user:&quot; + userId; RReadWriteLock rwLock = redissonClient.getReadWriteLock(lockKey); RLock readLock = rwLock.readLock(); try { readLock.lock(5, TimeUnit.SECONDS); // 加读锁，防止同时写入 User user = redisService.get(key); // 先查缓存 if (user != null) { return user; } // 缓存未命中 → 查数据库并回写缓存 user = userRepository.findById(userId); if (user != null) { redisService.set(key, user, 10, TimeUnit.MINUTES); } return user; } finally { readLock.unlock(); // 释放读锁 } } // 写操作：加“写锁” public void updateUser(User user) { Long userId = user.getId(); String key = &quot;user:&quot; + userId; String lockKey = &quot;lock:user:&quot; + userId; RReadWriteLock rwLock = redissonClient.getReadWriteLock(lockKey); RLock writeLock = rwLock.writeLock(); try { writeLock.lock(10, TimeUnit.SECONDS); // 加写锁，防止并发读/写 redisService.del(key); // 删除缓存（第一次） userRepository.save(user); // 更新数据库 // 第二次删除可延迟做（避免并发写入旧值） Thread.sleep(500); // 模拟延迟 redisService.del(key); // 延迟删除（第二次） } catch (InterruptedException e) { e.printStackTrace(); } finally { writeLock.unlock(); // 释放写锁 } }} 中间件解决方案 异步通知保证数据的最终一致性 canal是基于mysql的主从同步来实现的 二进制日志（BINLOG）记录了所有的 DDL（数据定义语言）语句和 DML（数据操纵语言）语句，但不包括数据查询（SELECT、SHOW）语句。","link":"/posts/redis%E8%AF%BB%E5%86%99%E4%B8%80%E8%87%B4%E9%97%AE%E9%A2%98/"}],"tags":[{"name":"redis","slug":"redis","link":"/tags/redis/"},{"name":"Hexo","slug":"Hexo","link":"/tags/Hexo/"}],"categories":[{"name":"redis笔记","slug":"redis笔记","link":"/categories/redis%E7%AC%94%E8%AE%B0/"},{"name":"Hexo教程","slug":"Hexo教程","link":"/categories/Hexo%E6%95%99%E7%A8%8B/"},{"name":"redis教程","slug":"redis教程","link":"/categories/redis%E6%95%99%E7%A8%8B/"},{"name":"redis的应用","slug":"redis的应用","link":"/categories/redis%E7%9A%84%E5%BA%94%E7%94%A8/"},{"name":"redis的问题方案","slug":"redis的问题方案","link":"/categories/redis%E7%9A%84%E9%97%AE%E9%A2%98%E6%96%B9%E6%A1%88/"}],"pages":[{"title":"categories","text":"","link":"/categories/index.html"}]}